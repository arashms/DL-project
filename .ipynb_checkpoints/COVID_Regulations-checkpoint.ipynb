{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/arashms/DL-project/blob/main/COVID_Regulations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbEqmVApz_64"
   },
   "source": [
    "# 1. Install and Import libraries and define parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nYK2n3Y0Ei9"
   },
   "source": [
    "### Install & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwUDsD-40hk0",
    "outputId": "7296624a-4d18-472d-81bc-a48abf238eb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
      "\r",
      "\u001b[K     |▏                               | 10kB 15.1MB/s eta 0:00:01\r",
      "\u001b[K     |▎                               | 20kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 30kB 22.5MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 40kB 23.8MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 51kB 25.8MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 61kB 18.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 71kB 18.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 81kB 19.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 92kB 16.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 102kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 112kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 122kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 133kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 143kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 153kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 163kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 174kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 184kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 194kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 204kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 215kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 225kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 235kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 245kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 256kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 266kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 276kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 286kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 296kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 307kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 317kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 327kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 337kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 348kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 358kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 368kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 378kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 389kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 399kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 409kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 419kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 430kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 440kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 450kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 460kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 471kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 481kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 491kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 501kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 512kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 522kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 532kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 542kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 552kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 563kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 573kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 583kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 593kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 604kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 614kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 624kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 634kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 645kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 655kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 665kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 675kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 686kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 696kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 706kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 716kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 727kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 737kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 747kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 757kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 768kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 778kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 788kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 798kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 808kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 819kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 829kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 839kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 849kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 860kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 870kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 880kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 890kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 901kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 911kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 921kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 931kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 942kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 952kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 962kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 972kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 983kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 993kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 1.0MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 1.0MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 1.0MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 1.0MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 1.0MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 1.1MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 1.1MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 1.1MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 1.1MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 1.1MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 1.1MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 1.1MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 1.1MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 1.1MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 1.1MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 1.2MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 1.2MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 1.2MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 1.2MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 1.2MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 1.2MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 1.2MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 1.2MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 1.2MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 1.2MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 1.3MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 1.3MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 1.3MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 1.3MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 1.3MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 1.3MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 1.3MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 1.3MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 1.3MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 1.4MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 1.4MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 1.4MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 1.4MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 1.4MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 1.4MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 1.4MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 1.4MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 1.4MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 1.4MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 1.5MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 1.5MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 1.5MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 1.5MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 1.5MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 1.5MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 1.5MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 1.5MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 1.5MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 1.5MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 1.6MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 1.6MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 1.6MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 1.6MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.6MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.6MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 1.6MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 1.6MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 1.6MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 1.6MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.7MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.7MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 1.7MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 1.7MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 1.7MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 1.7MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.7MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.7MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 1.7MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 1.8MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 1.8MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 1.8MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.8MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.8MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 1.8MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.8MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 1.8MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.8MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 1.8MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.9MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 1.9MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 1.9MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 1.9MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 1.9MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 1.9MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.9MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 1.9MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 1.9MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 1.9MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 2.0MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 2.0MB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 2.0MB 17.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 32.6MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 36.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=f8aff961e15116c3bdcf0120a3cf042ba97b84323f919795f541730fd46da90c\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.44 tokenizers-0.10.1 transformers-4.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Duysy8f6zlTc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.functional import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv \n",
    "import random\n",
    "from transformers import BertTokenizer, RobertaTokenizer\n",
    "from transformers import BertForNextSentencePrediction, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from scipy import stats\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gc\n",
    "import itertools\n",
    "import nltk\n",
    "import transformers\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DL7n3PVP_0Kl"
   },
   "source": [
    "### Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SCzaRwAj_5mA"
   },
   "outputs": [],
   "source": [
    "data_folder = '/content/drive/MyDrive/DL-project/'\n",
    "save_path = '/content/drive/MyDrive/DL-project/models/'\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 16\n",
    "learning_rate = 1e-6\n",
    "\n",
    "validation_ratio = 0.2\n",
    "\n",
    "max_length = 128\n",
    "max_sentence_length = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNlHSZJN_-lR"
   },
   "source": [
    "### Setting device, random seed, and runtime parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-DQtNqcAHPC",
    "outputId": "526742a6-6de7-45d0-b2e8-517193cc9068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available:  False\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Cuda available: \",torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current device: \",  torch.cuda.current_device())\n",
    "\n",
    "seed = 204920\n",
    "seed2 = 293652\n",
    "\n",
    "random.seed(seed2)\n",
    "np.random.seed(seed2)\n",
    "torch.manual_seed(seed2)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRwiF8MRC7Qm"
   },
   "source": [
    "# 2. Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPaNoawre29O",
    "outputId": "a7108bdd-8180-4bb2-be9c-937eb1f8d7d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheets in the dataset:    dict_keys(['About', 'Dataset', 'Dictionary'])\n",
      "Number of regulations in the dataset:  23923 \n",
      "\n",
      "     ID  ISO  ... ENTRY_DATE Alternative source\n",
      "0  4245  AFG  ... 2020-04-07                NaN\n",
      "1  4246  AFG  ... 2020-04-07                NaN\n",
      "2  4247  AFG  ... 2020-04-07                NaN\n",
      "3  4248  AFG  ... 2020-04-07                NaN\n",
      "4    23  AFG  ... 2020-03-14                NaN\n",
      "\n",
      "[5 rows x 18 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23923 entries, 0 to 23922\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   ID                  23923 non-null  int64         \n",
      " 1   ISO                 23923 non-null  object        \n",
      " 2   COUNTRY             23923 non-null  object        \n",
      " 3   REGION              23923 non-null  object        \n",
      " 4   ADMIN_LEVEL_NAME    3682 non-null   object        \n",
      " 5   PCODE               0 non-null      float64       \n",
      " 6   LOG_TYPE            23923 non-null  object        \n",
      " 7   CATEGORY            23923 non-null  object        \n",
      " 8   MEASURE             23923 non-null  object        \n",
      " 9   TARGETED_POP_GROUP  7556 non-null   object        \n",
      " 10  COMMENTS            23799 non-null  object        \n",
      " 11  NON_COMPLIANCE      22764 non-null  object        \n",
      " 12  DATE_IMPLEMENTED    23630 non-null  datetime64[ns]\n",
      " 13  SOURCE              23900 non-null  object        \n",
      " 14  SOURCE_TYPE         23912 non-null  object        \n",
      " 15  LINK                23890 non-null  object        \n",
      " 16  ENTRY_DATE          23923 non-null  datetime64[ns]\n",
      " 17  Alternative source  1779 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(1), object(14)\n",
      "memory usage: 3.3+ MB\n",
      "\n",
      " None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder as le\n",
    "\n",
    "xl_file = pd.ExcelFile(data_folder + 'acaps_covid19_government_measures_dataset_0.xlsx')\n",
    "\n",
    "sheets = {sheet_name: xl_file.parse(sheet_name) \n",
    "          for sheet_name in xl_file.sheet_names}\n",
    "\n",
    "dataframe = sheets['Dataset']\n",
    "\n",
    "print('Sheets in the dataset:   ', sheets.keys())\n",
    "print('Number of regulations in the dataset: ', len(dataframe), '\\n')\n",
    "\n",
    "print(dataframe.head())\n",
    "print('\\n', dataframe.info(), '\\n')\n",
    "\n",
    "# print(list(dataframe['ID'][0:10]))\n",
    "# print(dataframe.iloc[0])\n",
    "\n",
    "dataset = {}\n",
    "for key in dataframe:\n",
    "    # dataframe[key] = le.fit_transform(dataframe[key].astype(str))\n",
    "    dataframe[key]=dataframe[key].astype('str')\n",
    "    dataset[key] = list(dataframe[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mng1lN_HLLr"
   },
   "source": [
    "# 3. Processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-6bU1Md9LFC"
   },
   "source": [
    "### Some statistics of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeJ4idtBHU-a",
    "outputId": "06ab3dbb-ed73-4132-bc22-5cbd09f2cbfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequency Stat of  ID\n",
      "Number of different values:  23923 \n",
      "\n",
      "9999 : % 0.00418007774944614\n",
      "9998 : % 0.00418007774944614\n",
      "9997 : % 0.00418007774944614\n",
      "9996 : % 0.00418007774944614\n",
      "9995 : % 0.00418007774944614\n",
      "9994 : % 0.00418007774944614\n",
      "9993 : % 0.00418007774944614\n",
      "9992 : % 0.00418007774944614\n",
      "9991 : % 0.00418007774944614\n",
      "9990 : % 0.00418007774944614\n",
      "\n",
      "Frequency Stat of  ISO\n",
      "Number of different values:  193 \n",
      "\n",
      "GBR : % 2.7379509258872217\n",
      "AUS : % 2.3157630731931613\n",
      "USA : % 2.03569786398027\n",
      "PHL : % 1.910295531496886\n",
      "DNK : % 1.5006479120511642\n",
      "CAN : % 1.379425657317226\n",
      "NZL : % 1.2665635580821804\n",
      "LKA : % 1.2665635580821804\n",
      "PRT : % 1.228942858337165\n",
      "MYS : % 1.2164026250888267\n",
      "\n",
      "Frequency Stat of  COUNTRY\n",
      "Number of different values:  193 \n",
      "\n",
      "United Kingdom : % 2.7379509258872217\n",
      "Australia : % 2.3157630731931613\n",
      "United States : % 2.03569786398027\n",
      "Philippines : % 1.910295531496886\n",
      "Denmark : % 1.5006479120511642\n",
      "Canada : % 1.379425657317226\n",
      "Sri Lanka : % 1.2665635580821804\n",
      "New Zealand : % 1.2665635580821804\n",
      "Portugal : % 1.228942858337165\n",
      "Malaysia : % 1.2164026250888267\n",
      "\n",
      "Frequency Stat of  REGION\n",
      "Number of different values:  6 \n",
      "\n",
      "Europe : % 32.03193579400577\n",
      "Americas : % 20.883668436232913\n",
      "Africa : % 16.737031308782342\n",
      "Asia : % 14.613551812063704\n",
      "Pacific : % 8.431216820632864\n",
      "Middle east : % 7.302595828282406\n",
      "\n",
      "Frequency Stat of  ADMIN_LEVEL_NAME\n",
      "Number of different values:  1332 \n",
      "\n",
      "nan : % 84.60895372653931\n",
      "Scotland : % 0.5726706516741211\n",
      "Wales : % 0.42636793044350624\n",
      "Northern Ireland : % 0.3929273084479371\n",
      "Vic : % 0.3260460644567989\n",
      "FBiH : % 0.3176859089579066\n",
      "Faroe Islands : % 0.21318396522175312\n",
      "England : % 0.2006437319734147\n",
      "Flanders : % 0.19228357647452243\n",
      "Tas : % 0.13376248798227647\n",
      "\n",
      "Frequency Stat of  PCODE\n",
      "Number of different values:  1 \n",
      "\n",
      "nan : % 100.0\n",
      "\n",
      "Frequency Stat of  LOG_TYPE\n",
      "Number of different values:  2 \n",
      "\n",
      "Introduction / extension of measures : % 81.2816118379802\n",
      "Phase-out measure : % 18.718388162019814\n",
      "\n",
      "Frequency Stat of  CATEGORY\n",
      "Number of different values:  6 \n",
      "\n",
      "Public health measures : % 33.248338419094594\n",
      "Social distancing : % 23.157630731931615\n",
      "Movement restrictions : % 21.565021109392635\n",
      "Governance and socio-economic measures : % 18.241859298582952\n",
      "Lockdown : % 3.6659281862642645\n",
      "Humanitarian exemption : % 0.12122225473393805\n",
      "\n",
      "Frequency Stat of  MEASURE\n",
      "Number of different values:  35 \n",
      "\n",
      "Economic measures : % 12.456631693349497\n",
      "Closure of businesses and public services : % 9.60581866822723\n",
      "Limit public gatherings : % 9.317393303515445\n",
      "Strengthening the public health system : % 7.733143836475358\n",
      "Isolation and quarantine policies : % 5.726706516741212\n",
      "Domestic travel restrictions : % 4.25531914893617\n",
      "General recommendations : % 3.9125527734815866\n",
      "Border closure : % 3.7453496635037413\n",
      "Other public health measures enforced : % 3.7369895080048487\n",
      "Schools closure : % 3.64920787526648\n",
      "\n",
      "Frequency Stat of  TARGETED_POP_GROUP\n",
      "Number of different values:  2 \n",
      "\n",
      "nan : % 68.41533252518497\n",
      "checked : % 31.58466747481503\n",
      "\n",
      "Frequency Stat of  COMMENTS\n",
      "Number of different values:  23288 \n",
      "\n",
      "nan : % 0.5183296409313213\n",
      "APEC economies agree to keep markets open and trade flowing : % 0.07942147723947665\n",
      "Pacific Islands Forum Leaders have invoked the Biketawa Declaration, to collectively respond to the COVID-19 pandemic as a major crisis to The Blue Pacific â€“ its peoples, wellbeing and economies.\n",
      "\n",
      "The Pacific Humanitarian Pathway on COVID-19 (PHP-C), under the Biketawa Declaration is the Regionâ€™s mechanism that will provide the enabling political environment and commitment to expedite assistance and cooperation between member countries in preparing for and responding to COVID-19, by enabling the provision of medical and humanitarian assistance from regional, international and development partners in a timely, safe, effective and equitable manner. : % 0.05852108849224596\n",
      "Joint Ministerial Statement affirming commitment to ensuring supply chain connectivity amidst the COVID-19 situation : % 0.03762069974501526\n",
      "Travel to and from this area is temporarily prohibited for the next 24 hours until further notice. : % 0.0209003887472307\n",
      "The leaders of Palau, Marshall Islands, Nauru, Kiribati, and the Federated States of Micronesia are working together to hold the 2020 Micronesian Presidentsâ€™ Summit, which will be the largest in-person meeting of Pacific leaders since the beginning of the COVID-19 pandemic. \n",
      "\n",
      "the leaders plan to take advantage of their COVID-19 free status, turning the event into a key forum for shared regional priorities including rapidly expanding debt-stress, leadership of the Pacific Islands Forum, and the possibility of regional travel-bubbles. : % 0.0209003887472307\n",
      "State of emergency declared : % 0.0209003887472307\n",
      "Sanitation and hygiene recommendations : % 0.0209003887472307\n",
      "PACER Plus ratified and will enter into force on 13 December 2020. Pacer Plus is a regional trade, development and economic cooperation agreement between Pacific Island Countries and Australia and New Zealand covering trade in goods, services and investment. : % 0.0209003887472307\n",
      "Economic support for cultural institutions : % 0.0209003887472307\n",
      "\n",
      "Frequency Stat of  NON_COMPLIANCE\n",
      "Number of different values:  21 \n",
      "\n",
      "Not applicable : % 55.41111064665803\n",
      "Not available  : % 14.003260460644569\n",
      "Not Available : % 7.436358316264682\n",
      "Not Applicable : % 7.139572796054007\n",
      "nan : % 4.844710111608076\n",
      "Fines : % 3.1266981565857126\n",
      "Refusal to Enter the Country : % 1.8057935877607323\n",
      "Up to detention : % 1.7305521882707018\n",
      "Other (add in comments) : % 1.4337666680600258\n",
      "Arrest/Detention : % 0.9823182711198428\n",
      "\n",
      "Frequency Stat of  DATE_IMPLEMENTED\n",
      "Number of different values:  353 \n",
      "\n",
      "2020-03-16 : % 1.4295865903105798\n",
      "2020-05-11 : % 1.404506123813903\n",
      "NaT : % 1.224762780587719\n",
      "2020-03-20 : % 1.1787819253438114\n",
      "2020-06-01 : % 1.166241692095473\n",
      "2020-05-18 : % 1.1286209923504578\n",
      "2020-05-04 : % 1.1244409146010115\n",
      "2020-03-18 : % 1.0700999038582117\n",
      "2020-06-15 : % 1.015758893115412\n",
      "2020-03-23 : % 1.0032186598670736\n",
      "\n",
      "Frequency Stat of  SOURCE\n",
      "Number of different values:  1920 \n",
      "\n",
      "Government : % 5.480081929523889\n",
      "GardaWorld : % 2.9176942691134053\n",
      "Garda World : % 2.8758934916189443\n",
      "US Embassy : % 2.658529448647745\n",
      "RNZ : % 2.600008360155499\n",
      "Ministry of Health : % 2.361743928437069\n",
      "International SOS : % 1.8977552982485475\n",
      "MoH : % 1.5090080675500563\n",
      "US Embassy  : % 1.4128662793127953\n",
      "Government Website : % 1.4128662793127953\n",
      "\n",
      "Frequency Stat of  SOURCE_TYPE\n",
      "Number of different values:  11 \n",
      "\n",
      "Government : % 65.30953475734648\n",
      "Media : % 23.747021694603518\n",
      "Other organisations : % 6.111273669690256\n",
      "Social media : % 2.1945408184592234\n",
      "Other Organisations : % 1.7723529657651633\n",
      "UN : % 0.44726831919073695\n",
      "Social Media : % 0.1254023324833842\n",
      "Other : % 0.1254023324833842\n",
      "media : % 0.09614178823726122\n",
      "nan : % 0.045980855243907534\n",
      "\n",
      "Frequency Stat of  LINK\n",
      "Number of different values:  13306 \n",
      "\n",
      "https://pandemic.internationalsos.com/2019-ncov/ncov-travel-restrictions-flight-operations-and-screening#MYS : % 1.8016135100112862\n",
      "https://pib.gov.in/PressReleseDetail.aspx?PRID=1607242 : % 0.3803870751995987\n",
      "https://www.deutschland.de/en/news/german-federal-government-informs-about-the-corona-crisis : % 0.27170505371399906\n",
      "https://pandemic.internationalsos.com/2019-ncov/ncov-travel-restrictions-flight-operations-and-screening : % 0.27170505371399906\n",
      "https://www.imf.org/en/Topics/imf-and-covid19/Policy-Responses-to-COVID-19 : % 0.23408435396898383\n",
      "https://hr.usembassy.gov/covid-19-information-2/ : % 0.20482380972286085\n",
      "https://jo.usembassy.gov/covid-19-information/ : % 0.18392342097563014\n",
      "https://iq.usembassy.gov/covid-19-information/ : % 0.17138318772729172\n",
      "https://ga.usembassy.gov/u-s-citizen-services/coronavirus-update/ : % 0.14630272123061488\n",
      "https://cy.usembassy.gov/covid-19-information/ : % 0.14630272123061488\n",
      "\n",
      "Frequency Stat of  ENTRY_DATE\n",
      "Number of different values:  237 \n",
      "\n",
      "2020-04-21 : % 2.056598252727501\n",
      "2020-04-17 : % 1.5508088450445179\n",
      "2020-03-23 : % 1.5340885340467332\n",
      "2020-05-12 : % 1.3836057350666722\n",
      "2020-03-24 : % 1.3627053463194416\n",
      "2020-03-16 : % 1.3083643355766417\n",
      "2020-03-25 : % 1.2665635580821804\n",
      "2020-03-20 : % 1.254023324833842\n",
      "2020-05-11 : % 1.2373030138360575\n",
      "2020-04-14 : % 1.2331229360866112\n",
      "\n",
      "Frequency Stat of  Alternative source\n",
      "Number of different values:  1278 \n",
      "\n",
      "nan : % 92.56364168373531\n",
      "https://www.liberianobserver.com/news/covid-19-in-liberia-govt-declares-national-health-emergency/ : % 0.0627011662416921\n",
      "https://www.angop.ao/angola/en_us/noticias/politica/2020/4/19/President-extends-state-emergency,6fa62485-4c62-4bbc-8759-2d098a2846dc.html : % 0.05434101074279982\n",
      "https://pandemic.internationalsos.com/2019-ncov/ncov-travel-restrictions-flight-operations-and-screening#MYS : % 0.050160932993353675\n",
      "https://www.mhlw.go.jp/stf/seisakunitsuite/bunya/newpage_00032.html : % 0.03762069974501526\n",
      "https://www.gabonmediatime.com/covid-19-lintegralite-de-lallocution-du-premier-ministre-sur-la-mise-en-oeuvre-des-mesures-daccompagnement/ : % 0.03762069974501526\n",
      "https://twitter.com/PrimatureRwanda/status/1273030174800519170 : % 0.03762069974501526\n",
      "https://www.stopcoronavirusrdc.info/mesures-de-protection-contre-le-coronavirus : % 0.03344062199556912\n",
      "https://www.boliviasegura.gob.bo/ : % 0.03344062199556912\n",
      "https://covid19.min-saude.pt/wp-content/uploads/2020/03/Plano-de-Conting%C3%AAncia-Novo-Coronavirus_Covid-19.pdf : % 0.03344062199556912\n"
     ]
    }
   ],
   "source": [
    "def get_frequency_stat(attr):\n",
    "\n",
    "    freq_dic = {}\n",
    "    for value in dataset[attr]:\n",
    "        if value in freq_dic:\n",
    "            freq_dic[value] += 1\n",
    "        else:\n",
    "            freq_dic[value] = 1\n",
    "    \n",
    "    values = []\n",
    "    freqs = []\n",
    "\n",
    "    for key in freq_dic:\n",
    "        values.append(key)\n",
    "        freqs.append(freq_dic[key])\n",
    "\n",
    "    freqs, values = (list(t) for t in zip(*sorted(zip(freqs, values))))\n",
    "    freqs, values = freqs[::-1], values[::-1]\n",
    "    sumf = sum(freqs)\n",
    "\n",
    "    print('\\nFrequency Stat of ', attr)\n",
    "    print('Number of different values: ', len(values), '\\n')\n",
    "\n",
    "    for i in range(min(len(values), 10)):\n",
    "        print(values[i], ': %', 100 * freqs[i] / sumf)\n",
    "\n",
    "\n",
    "# print(dataframe['SOURCE'].value_counts())\n",
    "for key in dataset:\n",
    "    get_frequency_stat(key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ht8fiHA9VS-"
   },
   "source": [
    "### Classifying regulations based on Measure and Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNPFkhjy9lQr",
    "outputId": "0f38c29e-c8a0-4a84-9b27-70e688248655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "CATEGORY:  Public health measures  MEASURE:  Awareness campaigns  % 3.260460644567989\n",
      "CATEGORY:  Public health measures  MEASURE:  Health screenings in airports and border crossings  % 1.617690089035656\n",
      "CATEGORY:  Public health measures  MEASURE:  Strengthening the public health system  % 7.733143836475358\n",
      "CATEGORY:  Public health measures  MEASURE:  Isolation and quarantine policies  % 5.726706516741212\n",
      "CATEGORY:  Public health measures  MEASURE:  Other public health measures enforced  % 3.7369895080048487\n",
      "CATEGORY:  Public health measures  MEASURE:  General recommendations  % 3.9125527734815866\n",
      "CATEGORY:  Public health measures  MEASURE:  Requirement to wear protective gear in public  % 2.98875559085399\n",
      "CATEGORY:  Public health measures  MEASURE:  Testing policy  % 2.5038665719182376\n",
      "CATEGORY:  Public health measures  MEASURE:  Amendments to funeral and burial regulations  % 0.568490573924675\n",
      "CATEGORY:  Public health measures  MEASURE:  Mass population testing  % 0.5893909626719057\n",
      "CATEGORY:  Public health measures  MEASURE:  Psychological assistance and medical social work  % 0.597751118170798\n",
      "CATEGORY:  Public health measures  MEASURE:  Obligatory medical tests not related to COVID-19  % 0.012540233248338419\n",
      "10\n",
      "CATEGORY:  Movement restrictions  MEASURE:  International flights suspension  % 3.143418467583497\n",
      "CATEGORY:  Movement restrictions  MEASURE:  Border checks  % 0.44308824144129083\n",
      "CATEGORY:  Movement restrictions  MEASURE:  Surveillance and monitoring  % 2.332483384190946\n",
      "CATEGORY:  Movement restrictions  MEASURE:  Border closure  % 3.7453496635037413\n",
      "CATEGORY:  Movement restrictions  MEASURE:  Domestic travel restrictions  % 4.25531914893617\n",
      "CATEGORY:  Movement restrictions  MEASURE:  Checkpoints within the country  % 0.28842536471178365\n",
      "CATEGORY:  Movement restrictions  MEASURE:  Curfews  % 3.268820800066881\n",
      "CATEGORY:  Movement restrictions  MEASURE:  Visa restrictions  % 2.4411654056765455\n",
      "CATEGORY:  Movement restrictions  MEASURE:  Additional health/documents requirements upon arrival  % 1.61351001128621\n",
      "CATEGORY:  Movement restrictions  MEASURE:  Complete border closure  % 0.03344062199556912\n",
      "5\n",
      "CATEGORY:  Governance and socio-economic measures  MEASURE:  Emergency administrative structures activated or established  % 3.0639969903440205\n",
      "CATEGORY:  Governance and socio-economic measures  MEASURE:  State of emergency declared  % 1.9646365422396856\n",
      "CATEGORY:  Governance and socio-economic measures  MEASURE:  Limit product imports/exports  % 0.28842536471178365\n",
      "CATEGORY:  Governance and socio-economic measures  MEASURE:  Economic measures  % 12.456631693349497\n",
      "CATEGORY:  Governance and socio-economic measures  MEASURE:  Military deployment  % 0.46816870793796767\n",
      "4\n",
      "CATEGORY:  Social distancing  MEASURE:  Limit public gatherings  % 9.317393303515445\n",
      "CATEGORY:  Social distancing  MEASURE:  Schools closure  % 3.64920787526648\n",
      "CATEGORY:  Social distancing  MEASURE:  Changes in prison-related policies  % 0.5852108849224595\n",
      "CATEGORY:  Social distancing  MEASURE:  Closure of businesses and public services  % 9.60581866822723\n",
      "3\n",
      "CATEGORY:  Lockdown  MEASURE:  Partial lockdown  % 2.9385946578606363\n",
      "CATEGORY:  Lockdown  MEASURE:  Full lockdown  % 0.6228315846674748\n",
      "CATEGORY:  Lockdown  MEASURE:  Lockdown of refugee/idp camps or other minorities  % 0.1045019437361535\n",
      "1\n",
      "CATEGORY:  Humanitarian exemption  MEASURE:  Humanitarian exemptions  % 0.12122225473393805\n"
     ]
    }
   ],
   "source": [
    "regulation_types = {}\n",
    "\n",
    "for i in range(len(dataset['ID'])):\n",
    "\n",
    "    category = dataset['CATEGORY'][i]\n",
    "    measure = dataset['MEASURE'][i]\n",
    "\n",
    "    if category not in regulation_types:\n",
    "        regulation_types[category] = {}\n",
    "    \n",
    "    if measure not in regulation_types[category]:\n",
    "        regulation_types[category][measure] = []\n",
    "    \n",
    "    regulation_types[category][measure].append(i)\n",
    "\n",
    "for category in regulation_types:\n",
    "\n",
    "    print(len(regulation_types[category]))\n",
    "    \n",
    "    for measure in regulation_types[category]:\n",
    "        print('CATEGORY: ', category, ' MEASURE: ', measure, ' %',\n",
    "              100 * len(regulation_types[category][measure]) / len(dataset['ID']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Comment embeddings from DeBerta model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of relugations that the their comment is not null 23799\n"
     ]
    }
   ],
   "source": [
    "xl_file = pd.ExcelFile(\"acaps_covid19_government_measures_dataset_0.xlsx\")\n",
    "\n",
    "dfs = {sheet_name: xl_file.parse(sheet_name) \n",
    "          for sheet_name in xl_file.sheet_names}\n",
    "\n",
    "\n",
    "dataset = dfs['Dataset']\n",
    "\n",
    "# using ids list you can find the id of each comment\n",
    "ids = list(dataset.loc[dataset['COMMENTS'].notna()][\"ID\"])\n",
    "\n",
    "# the list contating all not nan comments\n",
    "comments = list(dataset.loc[dataset['COMMENTS'].notna()][\"COMMENTS\"])\n",
    "\n",
    "print(f'number of relugations that the their comment is not null {len(comments)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.DebertaTokenizer.from_pretrained('microsoft/deberta-base') \n",
    "max_length = 64\n",
    "train_encodings = tokenizer(comments, add_special_tokens=True, return_token_type_ids=False, truncation=True, padding=True, max_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "#         self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "#         if self.labels != None:\n",
    "#           item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(self.labels)\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NSPDataset(train_encodings)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DeBerta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['deberta.embeddings.position_embeddings.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): DebertaModel(\n",
       "    (embeddings): DebertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
       "      (LayerNorm): DebertaLayerNorm()\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(1024, 768)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = transformers.DebertaModel.from_pretrained('microsoft/deberta-base')\n",
    "\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "#   print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  model = torch.nn.DataParallel(model)\n",
    "    \n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Comment Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "723it [01:44,  7.25it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "all_cls = []\n",
    "\n",
    "for iteration, batch in tqdm(enumerate(train_loader)):\n",
    "    \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        last_hidden_state = model(input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        cls_tokens = last_hidden_state[:,0,:].detach()\n",
    "        \n",
    "        all_cls.append(cls_tokens)\n",
    "\n",
    "        \n",
    "# out_cls is a matrix of size number_of_not_null_comments (23799) X size_of_hidden_state_of_BERT (768)\n",
    "# In this matrix, for each comment we have an embedding vector.\n",
    "# Use \"ids\" list to map each comment with its ids.\n",
    "out_cls = torch.cat(all_cls, 0)\n",
    "\n",
    "print(\"shape of output matrix :\", out_cls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMtABEuzTdzbIHD8vubLKu3",
   "include_colab_link": true,
   "mount_file_id": "1b1t15b3A22-048tEj4ns52m1vzJ6uFqY",
   "name": "COVID-Regulations.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "hugging",
   "language": "python",
   "name": "hugging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
