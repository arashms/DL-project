{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID-Regulations.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arashms/DL-project/blob/main/COVID_Regulations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbEqmVApz_64"
      },
      "source": [
        "# 1. Install and Import libraries and define parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nYK2n3Y0Ei9"
      },
      "source": [
        "### Install & Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwUDsD-40hk0",
        "outputId": "94d2f237-6674-47ac-c17d-ddd07e2bfe0a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duysy8f6zlTc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.nn.functional import softmax\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import csv \n",
        "import random\n",
        "from transformers import BertTokenizer, RobertaTokenizer\n",
        "from transformers import BertForNextSentencePrediction, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from scipy import stats\n",
        "import time\n",
        "import datetime\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "import gc\n",
        "import itertools\n",
        "import nltk\n",
        "import transformers\n",
        "# nltk.download('punkt')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL7n3PVP_0Kl"
      },
      "source": [
        "### Setting Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCzaRwAj_5mA"
      },
      "source": [
        "data_folder = '/content/drive/MyDrive/DL-project/'\n",
        "save_path = '/content/drive/MyDrive/DL-project/models/'\n",
        "\n",
        "epochs = 1\n",
        "batch_size = 16\n",
        "learning_rate = 1e-6\n",
        "\n",
        "validation_ratio = 0.2\n",
        "\n",
        "max_length = 128\n",
        "max_sentence_length = 64"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNlHSZJN_-lR"
      },
      "source": [
        "### Setting device, random seed, and runtime parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-DQtNqcAHPC",
        "outputId": "c0e40529-003a-4301-9ba4-39a91bf1cdc9"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Cuda available: \",torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Current device: \",  torch.cuda.current_device())\n",
        "\n",
        "seed = 204920\n",
        "seed2 = 293652\n",
        "\n",
        "random.seed(seed2)\n",
        "np.random.seed(seed2)\n",
        "torch.manual_seed(seed2)\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    torch.cuda.manual_seed_all(seed)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda available:  True\n",
            "Current device:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRwiF8MRC7Qm"
      },
      "source": [
        "# 2. Reading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaNTibrAtpHk",
        "outputId": "25de5186-a5eb-44e0-9e33-dcf7e46b31d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPaNoawre29O",
        "outputId": "7de7edbd-d9fa-41d7-923a-cbf10d012b83"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder as le\n",
        "!cp  /content/drive/MyDrive/DL-project/Combined.xlsx Combined.xlsx\n",
        "!cp  /content/drive/MyDrive/DL-project/acaps_covid19_government_measures_dataset_0.xlsx acaps_covid19_government_measures_dataset_0.xlsx\n",
        "\n",
        "xl_file = pd.ExcelFile('acaps_covid19_government_measures_dataset_0.xlsx')\n",
        "\n",
        "sheets = {sheet_name: xl_file.parse(sheet_name) \n",
        "          for sheet_name in xl_file.sheet_names}\n",
        "\n",
        "dataframe = sheets['Dataset']\n",
        "\n",
        "print('Sheets in the dataset:   ', sheets.keys())\n",
        "print('Number of regulations in the dataset: ', len(dataframe), '\\n')\n",
        "\n",
        "print(dataframe.head())\n",
        "print('\\n', dataframe.info(), '\\n')\n",
        "\n",
        "# print(list(dataframe['ID'][0:10]))\n",
        "# print(dataframe.iloc[0])\n",
        "\n",
        "dataset = {}\n",
        "for key in dataframe:\n",
        "    # dataframe[key] = le.fit_transform(dataframe[key].astype(str))\n",
        "    dataframe[key]=dataframe[key].astype('str')\n",
        "    dataset[key] = list(dataframe[key])\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sheets in the dataset:    dict_keys(['About', 'Dataset', 'Dictionary'])\n",
            "Number of regulations in the dataset:  23923 \n",
            "\n",
            "     ID  ISO  ... ENTRY_DATE Alternative source\n",
            "0  4245  AFG  ... 2020-04-07                NaN\n",
            "1  4246  AFG  ... 2020-04-07                NaN\n",
            "2  4247  AFG  ... 2020-04-07                NaN\n",
            "3  4248  AFG  ... 2020-04-07                NaN\n",
            "4    23  AFG  ... 2020-03-14                NaN\n",
            "\n",
            "[5 rows x 18 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23923 entries, 0 to 23922\n",
            "Data columns (total 18 columns):\n",
            " #   Column              Non-Null Count  Dtype         \n",
            "---  ------              --------------  -----         \n",
            " 0   ID                  23923 non-null  int64         \n",
            " 1   ISO                 23923 non-null  object        \n",
            " 2   COUNTRY             23923 non-null  object        \n",
            " 3   REGION              23923 non-null  object        \n",
            " 4   ADMIN_LEVEL_NAME    3682 non-null   object        \n",
            " 5   PCODE               0 non-null      float64       \n",
            " 6   LOG_TYPE            23923 non-null  object        \n",
            " 7   CATEGORY            23923 non-null  object        \n",
            " 8   MEASURE             23923 non-null  object        \n",
            " 9   TARGETED_POP_GROUP  7556 non-null   object        \n",
            " 10  COMMENTS            23799 non-null  object        \n",
            " 11  NON_COMPLIANCE      22764 non-null  object        \n",
            " 12  DATE_IMPLEMENTED    23630 non-null  datetime64[ns]\n",
            " 13  SOURCE              23900 non-null  object        \n",
            " 14  SOURCE_TYPE         23912 non-null  object        \n",
            " 15  LINK                23890 non-null  object        \n",
            " 16  ENTRY_DATE          23923 non-null  datetime64[ns]\n",
            " 17  Alternative source  1779 non-null   object        \n",
            "dtypes: datetime64[ns](2), float64(1), int64(1), object(14)\n",
            "memory usage: 3.3+ MB\n",
            "\n",
            " None \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mng1lN_HLLr"
      },
      "source": [
        "# 3. Processing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-6bU1Md9LFC"
      },
      "source": [
        "### Some statistics of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeJ4idtBHU-a",
        "outputId": "18967bc0-80fa-43e6-bdb5-aee98fc72602"
      },
      "source": [
        "def get_frequency_stat(attr):\n",
        "\n",
        "    freq_dic = {}\n",
        "    for value in dataset[attr]:\n",
        "        if value in freq_dic:\n",
        "            freq_dic[value] += 1\n",
        "        else:\n",
        "            freq_dic[value] = 1\n",
        "    \n",
        "    values = []\n",
        "    freqs = []\n",
        "\n",
        "    for key in freq_dic:\n",
        "        values.append(key)\n",
        "        freqs.append(freq_dic[key])\n",
        "\n",
        "    freqs, values = (list(t) for t in zip(*sorted(zip(freqs, values))))\n",
        "    freqs, values = freqs[::-1], values[::-1]\n",
        "    sumf = sum(freqs)\n",
        "\n",
        "    print('\\nFrequency Stat of ', attr)\n",
        "    print('Number of different values: ', len(values), '\\n')\n",
        "\n",
        "    for i in range(min(len(values), 10)):\n",
        "        print(values[i], ': %', 100 * freqs[i] / sumf)\n",
        "\n",
        "\n",
        "# print(dataframe['SOURCE'].value_counts())\n",
        "for key in dataset:\n",
        "    get_frequency_stat(key)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Frequency Stat of  ID\n",
            "Number of different values:  23923 \n",
            "\n",
            "9999 : % 0.00418007774944614\n",
            "9998 : % 0.00418007774944614\n",
            "9997 : % 0.00418007774944614\n",
            "9996 : % 0.00418007774944614\n",
            "9995 : % 0.00418007774944614\n",
            "9994 : % 0.00418007774944614\n",
            "9993 : % 0.00418007774944614\n",
            "9992 : % 0.00418007774944614\n",
            "9991 : % 0.00418007774944614\n",
            "9990 : % 0.00418007774944614\n",
            "\n",
            "Frequency Stat of  ISO\n",
            "Number of different values:  193 \n",
            "\n",
            "GBR : % 2.7379509258872217\n",
            "AUS : % 2.3157630731931613\n",
            "USA : % 2.03569786398027\n",
            "PHL : % 1.910295531496886\n",
            "DNK : % 1.5006479120511642\n",
            "CAN : % 1.379425657317226\n",
            "NZL : % 1.2665635580821804\n",
            "LKA : % 1.2665635580821804\n",
            "PRT : % 1.228942858337165\n",
            "MYS : % 1.2164026250888267\n",
            "\n",
            "Frequency Stat of  COUNTRY\n",
            "Number of different values:  193 \n",
            "\n",
            "United Kingdom : % 2.7379509258872217\n",
            "Australia : % 2.3157630731931613\n",
            "United States : % 2.03569786398027\n",
            "Philippines : % 1.910295531496886\n",
            "Denmark : % 1.5006479120511642\n",
            "Canada : % 1.379425657317226\n",
            "Sri Lanka : % 1.2665635580821804\n",
            "New Zealand : % 1.2665635580821804\n",
            "Portugal : % 1.228942858337165\n",
            "Malaysia : % 1.2164026250888267\n",
            "\n",
            "Frequency Stat of  REGION\n",
            "Number of different values:  6 \n",
            "\n",
            "Europe : % 32.03193579400577\n",
            "Americas : % 20.883668436232913\n",
            "Africa : % 16.737031308782342\n",
            "Asia : % 14.613551812063704\n",
            "Pacific : % 8.431216820632864\n",
            "Middle east : % 7.302595828282406\n",
            "\n",
            "Frequency Stat of  ADMIN_LEVEL_NAME\n",
            "Number of different values:  1332 \n",
            "\n",
            "nan : % 84.60895372653931\n",
            "Scotland : % 0.5726706516741211\n",
            "Wales : % 0.42636793044350624\n",
            "Northern Ireland : % 0.3929273084479371\n",
            "Vic : % 0.3260460644567989\n",
            "FBiH : % 0.3176859089579066\n",
            "Faroe Islands : % 0.21318396522175312\n",
            "England : % 0.2006437319734147\n",
            "Flanders : % 0.19228357647452243\n",
            "Tas : % 0.13376248798227647\n",
            "\n",
            "Frequency Stat of  PCODE\n",
            "Number of different values:  1 \n",
            "\n",
            "nan : % 100.0\n",
            "\n",
            "Frequency Stat of  LOG_TYPE\n",
            "Number of different values:  2 \n",
            "\n",
            "Introduction / extension of measures : % 81.2816118379802\n",
            "Phase-out measure : % 18.718388162019814\n",
            "\n",
            "Frequency Stat of  CATEGORY\n",
            "Number of different values:  6 \n",
            "\n",
            "Public health measures : % 33.248338419094594\n",
            "Social distancing : % 23.157630731931615\n",
            "Movement restrictions : % 21.565021109392635\n",
            "Governance and socio-economic measures : % 18.241859298582952\n",
            "Lockdown : % 3.6659281862642645\n",
            "Humanitarian exemption : % 0.12122225473393805\n",
            "\n",
            "Frequency Stat of  MEASURE\n",
            "Number of different values:  35 \n",
            "\n",
            "Economic measures : % 12.456631693349497\n",
            "Closure of businesses and public services : % 9.60581866822723\n",
            "Limit public gatherings : % 9.317393303515445\n",
            "Strengthening the public health system : % 7.733143836475358\n",
            "Isolation and quarantine policies : % 5.726706516741212\n",
            "Domestic travel restrictions : % 4.25531914893617\n",
            "General recommendations : % 3.9125527734815866\n",
            "Border closure : % 3.7453496635037413\n",
            "Other public health measures enforced : % 3.7369895080048487\n",
            "Schools closure : % 3.64920787526648\n",
            "\n",
            "Frequency Stat of  TARGETED_POP_GROUP\n",
            "Number of different values:  2 \n",
            "\n",
            "nan : % 68.41533252518497\n",
            "checked : % 31.58466747481503\n",
            "\n",
            "Frequency Stat of  COMMENTS\n",
            "Number of different values:  23288 \n",
            "\n",
            "nan : % 0.5183296409313213\n",
            "APEC economies agree to keep markets open and trade flowing : % 0.07942147723947665\n",
            "Pacific Islands Forum Leaders have invoked the Biketawa Declaration, to collectively respond to the COVID-19 pandemic as a major crisis to The Blue Pacific â€“ its peoples, wellbeing and economies.\n",
            "\n",
            "The Pacific Humanitarian Pathway on COVID-19 (PHP-C), under the Biketawa Declaration is the Regionâ€™s mechanism that will provide the enabling political environment and commitment to expedite assistance and cooperation between member countries in preparing for and responding to COVID-19, by enabling the provision of medical and humanitarian assistance from regional, international and development partners in a timely, safe, effective and equitable manner. : % 0.05852108849224596\n",
            "Joint Ministerial Statement affirming commitment to ensuring supply chain connectivity amidst the COVID-19 situation : % 0.03762069974501526\n",
            "Travel to and from this area is temporarily prohibited for the next 24 hours until further notice. : % 0.0209003887472307\n",
            "The leaders of Palau, Marshall Islands, Nauru, Kiribati, and the Federated States of Micronesia are working together to hold the 2020 Micronesian Presidentsâ€™ Summit, which will be the largest in-person meeting of Pacific leaders since the beginning of the COVID-19 pandemic. \n",
            "\n",
            "the leaders plan to take advantage of their COVID-19 free status, turning the event into a key forum for shared regional priorities including rapidly expanding debt-stress, leadership of the Pacific Islands Forum, and the possibility of regional travel-bubbles. : % 0.0209003887472307\n",
            "State of emergency declared : % 0.0209003887472307\n",
            "Sanitation and hygiene recommendations : % 0.0209003887472307\n",
            "PACER Plus ratified and will enter into force on 13 December 2020. Pacer Plus is a regional trade, development and economic cooperation agreement between Pacific Island Countries and Australia and New Zealand covering trade in goods, services and investment. : % 0.0209003887472307\n",
            "Economic support for cultural institutions : % 0.0209003887472307\n",
            "\n",
            "Frequency Stat of  NON_COMPLIANCE\n",
            "Number of different values:  21 \n",
            "\n",
            "Not applicable : % 55.41111064665803\n",
            "Not available  : % 14.003260460644569\n",
            "Not Available : % 7.436358316264682\n",
            "Not Applicable : % 7.139572796054007\n",
            "nan : % 4.844710111608076\n",
            "Fines : % 3.1266981565857126\n",
            "Refusal to Enter the Country : % 1.8057935877607323\n",
            "Up to detention : % 1.7305521882707018\n",
            "Other (add in comments) : % 1.4337666680600258\n",
            "Arrest/Detention : % 0.9823182711198428\n",
            "\n",
            "Frequency Stat of  DATE_IMPLEMENTED\n",
            "Number of different values:  353 \n",
            "\n",
            "2020-03-16 : % 1.4295865903105798\n",
            "2020-05-11 : % 1.404506123813903\n",
            "NaT : % 1.224762780587719\n",
            "2020-03-20 : % 1.1787819253438114\n",
            "2020-06-01 : % 1.166241692095473\n",
            "2020-05-18 : % 1.1286209923504578\n",
            "2020-05-04 : % 1.1244409146010115\n",
            "2020-03-18 : % 1.0700999038582117\n",
            "2020-06-15 : % 1.015758893115412\n",
            "2020-03-23 : % 1.0032186598670736\n",
            "\n",
            "Frequency Stat of  SOURCE\n",
            "Number of different values:  1920 \n",
            "\n",
            "Government : % 5.480081929523889\n",
            "GardaWorld : % 2.9176942691134053\n",
            "Garda World : % 2.8758934916189443\n",
            "US Embassy : % 2.658529448647745\n",
            "RNZ : % 2.600008360155499\n",
            "Ministry of Health : % 2.361743928437069\n",
            "International SOS : % 1.8977552982485475\n",
            "MoH : % 1.5090080675500563\n",
            "US Embassy  : % 1.4128662793127953\n",
            "Government Website : % 1.4128662793127953\n",
            "\n",
            "Frequency Stat of  SOURCE_TYPE\n",
            "Number of different values:  11 \n",
            "\n",
            "Government : % 65.30953475734648\n",
            "Media : % 23.747021694603518\n",
            "Other organisations : % 6.111273669690256\n",
            "Social media : % 2.1945408184592234\n",
            "Other Organisations : % 1.7723529657651633\n",
            "UN : % 0.44726831919073695\n",
            "Social Media : % 0.1254023324833842\n",
            "Other : % 0.1254023324833842\n",
            "media : % 0.09614178823726122\n",
            "nan : % 0.045980855243907534\n",
            "\n",
            "Frequency Stat of  LINK\n",
            "Number of different values:  13306 \n",
            "\n",
            "https://pandemic.internationalsos.com/2019-ncov/ncov-travel-restrictions-flight-operations-and-screening#MYS : % 1.8016135100112862\n",
            "https://pib.gov.in/PressReleseDetail.aspx?PRID=1607242 : % 0.3803870751995987\n",
            "https://www.deutschland.de/en/news/german-federal-government-informs-about-the-corona-crisis : % 0.27170505371399906\n",
            "https://pandemic.internationalsos.com/2019-ncov/ncov-travel-restrictions-flight-operations-and-screening : % 0.27170505371399906\n",
            "https://www.imf.org/en/Topics/imf-and-covid19/Policy-Responses-to-COVID-19 : % 0.23408435396898383\n",
            "https://hr.usembassy.gov/covid-19-information-2/ : % 0.20482380972286085\n",
            "https://jo.usembassy.gov/covid-19-information/ : % 0.18392342097563014\n",
            "https://iq.usembassy.gov/covid-19-information/ : % 0.17138318772729172\n",
            "https://ga.usembassy.gov/u-s-citizen-services/coronavirus-update/ : % 0.14630272123061488\n",
            "https://cy.usembassy.gov/covid-19-information/ : % 0.14630272123061488\n",
            "\n",
            "Frequency Stat of  ENTRY_DATE\n",
            "Number of different values:  237 \n",
            "\n",
            "2020-04-21 : % 2.056598252727501\n",
            "2020-04-17 : % 1.5508088450445179\n",
            "2020-03-23 : % 1.5340885340467332\n",
            "2020-05-12 : % 1.3836057350666722\n",
            "2020-03-24 : % 1.3627053463194416\n",
            "2020-03-16 : % 1.3083643355766417\n",
            "2020-03-25 : % 1.2665635580821804\n",
            "2020-03-20 : % 1.254023324833842\n",
            "2020-05-11 : % 1.2373030138360575\n",
            "2020-04-14 : % 1.2331229360866112\n",
            "\n",
            "Frequency Stat of  Alternative source\n",
            "Number of different values:  1278 \n",
            "\n",
            "nan : % 92.56364168373531\n",
            "https://www.liberianobserver.com/news/covid-19-in-liberia-govt-declares-national-health-emergency/ : % 0.0627011662416921\n",
            "https://www.angop.ao/angola/en_us/noticias/politica/2020/4/19/President-extends-state-emergency,6fa62485-4c62-4bbc-8759-2d098a2846dc.html : % 0.05434101074279982\n",
            "https://pandemic.internationalsos.com/2019-ncov/ncov-travel-restrictions-flight-operations-and-screening#MYS : % 0.050160932993353675\n",
            "https://www.mhlw.go.jp/stf/seisakunitsuite/bunya/newpage_00032.html : % 0.03762069974501526\n",
            "https://www.gabonmediatime.com/covid-19-lintegralite-de-lallocution-du-premier-ministre-sur-la-mise-en-oeuvre-des-mesures-daccompagnement/ : % 0.03762069974501526\n",
            "https://twitter.com/PrimatureRwanda/status/1273030174800519170 : % 0.03762069974501526\n",
            "https://www.stopcoronavirusrdc.info/mesures-de-protection-contre-le-coronavirus : % 0.03344062199556912\n",
            "https://www.boliviasegura.gob.bo/ : % 0.03344062199556912\n",
            "https://covid19.min-saude.pt/wp-content/uploads/2020/03/Plano-de-Conting%C3%AAncia-Novo-Coronavirus_Covid-19.pdf : % 0.03344062199556912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ht8fiHA9VS-"
      },
      "source": [
        "### Classifying regulations based on Measure and Category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNPFkhjy9lQr",
        "outputId": "bb22cb4d-b734-42d2-847d-05d20b8f873b"
      },
      "source": [
        "regulation_types = {}\n",
        "\n",
        "for i in range(len(dataset['ID'])):\n",
        "\n",
        "    category = dataset['CATEGORY'][i]\n",
        "    measure = dataset['MEASURE'][i]\n",
        "\n",
        "    if category not in regulation_types:\n",
        "        regulation_types[category] = {}\n",
        "    \n",
        "    if measure not in regulation_types[category]:\n",
        "        regulation_types[category][measure] = []\n",
        "    \n",
        "    regulation_types[category][measure].append(i)\n",
        "\n",
        "for category in regulation_types:\n",
        "\n",
        "    print(len(regulation_types[category]))\n",
        "    \n",
        "    for measure in regulation_types[category]:\n",
        "        print('CATEGORY: ', category, ' MEASURE: ', measure, ' %',\n",
        "              100 * len(regulation_types[category][measure]) / len(dataset['ID']) )\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "CATEGORY:  Public health measures  MEASURE:  Awareness campaigns  % 3.260460644567989\n",
            "CATEGORY:  Public health measures  MEASURE:  Health screenings in airports and border crossings  % 1.617690089035656\n",
            "CATEGORY:  Public health measures  MEASURE:  Strengthening the public health system  % 7.733143836475358\n",
            "CATEGORY:  Public health measures  MEASURE:  Isolation and quarantine policies  % 5.726706516741212\n",
            "CATEGORY:  Public health measures  MEASURE:  Other public health measures enforced  % 3.7369895080048487\n",
            "CATEGORY:  Public health measures  MEASURE:  General recommendations  % 3.9125527734815866\n",
            "CATEGORY:  Public health measures  MEASURE:  Requirement to wear protective gear in public  % 2.98875559085399\n",
            "CATEGORY:  Public health measures  MEASURE:  Testing policy  % 2.5038665719182376\n",
            "CATEGORY:  Public health measures  MEASURE:  Amendments to funeral and burial regulations  % 0.568490573924675\n",
            "CATEGORY:  Public health measures  MEASURE:  Mass population testing  % 0.5893909626719057\n",
            "CATEGORY:  Public health measures  MEASURE:  Psychological assistance and medical social work  % 0.597751118170798\n",
            "CATEGORY:  Public health measures  MEASURE:  Obligatory medical tests not related to COVID-19  % 0.012540233248338419\n",
            "10\n",
            "CATEGORY:  Movement restrictions  MEASURE:  International flights suspension  % 3.143418467583497\n",
            "CATEGORY:  Movement restrictions  MEASURE:  Border checks  % 0.44308824144129083\n",
            "CATEGORY:  Movement restrictions  MEASURE:  Surveillance and monitoring  % 2.332483384190946\n",
            "CATEGORY:  Movement restrictions  MEASURE:  Border closure  % 3.7453496635037413\n",
            "CATEGORY:  Movement restrictions  MEASURE:  Domestic travel restrictions  % 4.25531914893617\n",
            "CATEGORY:  Movement restrictions  MEASURE:  Checkpoints within the country  % 0.28842536471178365\n",
            "CATEGORY:  Movement restrictions  MEASURE:  Curfews  % 3.268820800066881\n",
            "CATEGORY:  Movement restrictions  MEASURE:  Visa restrictions  % 2.4411654056765455\n",
            "CATEGORY:  Movement restrictions  MEASURE:  Additional health/documents requirements upon arrival  % 1.61351001128621\n",
            "CATEGORY:  Movement restrictions  MEASURE:  Complete border closure  % 0.03344062199556912\n",
            "5\n",
            "CATEGORY:  Governance and socio-economic measures  MEASURE:  Emergency administrative structures activated or established  % 3.0639969903440205\n",
            "CATEGORY:  Governance and socio-economic measures  MEASURE:  State of emergency declared  % 1.9646365422396856\n",
            "CATEGORY:  Governance and socio-economic measures  MEASURE:  Limit product imports/exports  % 0.28842536471178365\n",
            "CATEGORY:  Governance and socio-economic measures  MEASURE:  Economic measures  % 12.456631693349497\n",
            "CATEGORY:  Governance and socio-economic measures  MEASURE:  Military deployment  % 0.46816870793796767\n",
            "4\n",
            "CATEGORY:  Social distancing  MEASURE:  Limit public gatherings  % 9.317393303515445\n",
            "CATEGORY:  Social distancing  MEASURE:  Schools closure  % 3.64920787526648\n",
            "CATEGORY:  Social distancing  MEASURE:  Changes in prison-related policies  % 0.5852108849224595\n",
            "CATEGORY:  Social distancing  MEASURE:  Closure of businesses and public services  % 9.60581866822723\n",
            "3\n",
            "CATEGORY:  Lockdown  MEASURE:  Partial lockdown  % 2.9385946578606363\n",
            "CATEGORY:  Lockdown  MEASURE:  Full lockdown  % 0.6228315846674748\n",
            "CATEGORY:  Lockdown  MEASURE:  Lockdown of refugee/idp camps or other minorities  % 0.1045019437361535\n",
            "1\n",
            "CATEGORY:  Humanitarian exemption  MEASURE:  Humanitarian exemptions  % 0.12122225473393805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU2TB0dIac4m"
      },
      "source": [
        "# 4. Comment embeddings from DeBerta model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atc_6HJhac4m"
      },
      "source": [
        "### Loading Comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPM9lAl3ac4m",
        "outputId": "f8751b2c-de25-4335-b2be-e92bc7fbdbcc"
      },
      "source": [
        "xl_file = pd.ExcelFile(\"acaps_covid19_government_measures_dataset_0.xlsx\")\n",
        "\n",
        "dfs = {sheet_name: xl_file.parse(sheet_name) \n",
        "          for sheet_name in xl_file.sheet_names}\n",
        "\n",
        "\n",
        "dataset = dfs['Dataset']\n",
        "\n",
        "# using ids list you can find the id of each comment\n",
        "not_null_ids = list(dataset.loc[dataset['COMMENTS'].notna()][\"ID\"])\n",
        "\n",
        "# the list contating all not nan comments\n",
        "comments = list(dataset.loc[dataset['COMMENTS'].notna()][\"COMMENTS\"])\n",
        "\n",
        "print(f'number of relugations that the their comment is not null {len(comments)}')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of relugations that the their comment is not null 23799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ6aqRdgac4n"
      },
      "source": [
        "### Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzP53Wzsac4o"
      },
      "source": [
        "tokenizer = transformers.DebertaTokenizer.from_pretrained('microsoft/deberta-base') \n",
        "max_length = 64\n",
        "train_encodings = tokenizer(comments, add_special_tokens=True, return_token_type_ids=False, truncation=True, padding=True, max_length=max_length)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G5kUUQWac4p"
      },
      "source": [
        "### Creating pytorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crdsqJosac4p"
      },
      "source": [
        "class NSPDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "#         self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "#         if self.labels != None:\n",
        "#           item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        # return len(self.labels)\n",
        "        return len(self.encodings['input_ids'])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvcs4q22ac4q"
      },
      "source": [
        "train_dataset = NSPDataset(train_encodings)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06zqtx-rac4q"
      },
      "source": [
        "### Creating DeBerta Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKOTYuVwac4q",
        "outputId": "0a4e8813-b895-4d70-bf06-81cf548bc3e8"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = transformers.DebertaModel.from_pretrained('microsoft/deberta-base')\n",
        "\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "#   print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "  model = torch.nn.DataParallel(model)\n",
        "    \n",
        "model.to(device)\n",
        "model.train()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DebertaModel(\n",
              "  (embeddings): DebertaEmbeddings(\n",
              "    (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
              "    (LayerNorm): DebertaLayerNorm()\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (encoder): DebertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (1): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (2): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (3): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (4): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (5): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (6): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (7): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (8): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (9): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (10): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (11): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (rel_embeddings): Embedding(1024, 768)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5eHPqgNac4r"
      },
      "source": [
        "### Generating Comment Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6-aHVqtac4s",
        "outputId": "e7a2730a-c0d6-4c15-d5c1-9fbd968251ce"
      },
      "source": [
        "all_cls = []\n",
        "\n",
        "for iteration, batch in tqdm(enumerate(train_loader)):\n",
        "    \n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        last_hidden_state = model(input_ids, attention_mask=attention_mask).last_hidden_state\n",
        "        cls_tokens = last_hidden_state[:,0,:].detach()\n",
        "        \n",
        "        all_cls.append(cls_tokens)\n",
        "\n",
        "        \n",
        "# out_cls is a matrix of size number_of_not_null_comments (23799) X size_of_hidden_state_of_BERT (768)\n",
        "# In this matrix, for each comment we have an embedding vector.\n",
        "# Use \"ids\" list to map each comment with its ids.\n",
        "out_cls = torch.cat(all_cls, 0)\n",
        "\n",
        "print(\"shape of output matrix :\", out_cls.shape)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "744it [01:48,  6.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "shape of output matrix : torch.Size([23799, 768])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDVJI76uzlya"
      },
      "source": [
        "# 5. Preparing Input and Output Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl9-07Rd2XTa"
      },
      "source": [
        "### Creating feature maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3tXTJGF2i4q"
      },
      "source": [
        "category_map = {}\n",
        "measure_map = {}\n",
        "log_type_map = {}\n",
        "\n",
        "for i in range(len(dataset['ID'])):\n",
        "\n",
        "    category = dataset['CATEGORY'][i]\n",
        "    measure = dataset['MEASURE'][i]\n",
        "    log_type =dataset['LOG_TYPE'][i]\n",
        "\n",
        "    if category not in category_map:\n",
        "        category_map[category] = len(category_map.keys())\n",
        "    \n",
        "    if measure not in measure_map:\n",
        "        measure_map[measure] = len(measure_map.keys())\n",
        "\n",
        "    if log_type not in log_type_map:\n",
        "        log_type_map[log_type] = len(log_type_map.keys())\n",
        "\n",
        "\n",
        "id2index_map = {}\n",
        "\n",
        "for index, id in enumerate(dataset['ID']):\n",
        "    id2index_map[id] = index"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaG_QxoD4F9-"
      },
      "source": [
        "### Preparing input features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLssf_j1ac4s"
      },
      "source": [
        "message_embeddings = out_cls.tolist()\n",
        "categories = []\n",
        "measures = []\n",
        "log_types = []\n",
        "\n",
        "for id in not_null_ids:\n",
        "    index = id2index_map[id]\n",
        "\n",
        "    category = category_map[dataset['CATEGORY'][index]]\n",
        "    one_hot_category = [0 for i in range(len(category_map.keys()))]\n",
        "    one_hot_category[category] = 1\n",
        "    categories.append(one_hot_category)\n",
        "\n",
        "    measure = measure_map[dataset['MEASURE'][index]]\n",
        "    one_hot_measure = [0 for i in range(len(measure_map.keys()))]\n",
        "    one_hot_measure[measure] = 1\n",
        "    measures.append(one_hot_measure)\n",
        "\n",
        "    log_type = log_type_map[dataset['LOG_TYPE'][index]]\n",
        "    log_types.append(log_type)\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3gNJag6Jkn3"
      },
      "source": [
        "### Reading combined dataset & Preparing output labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQdbdXhlJjFJ",
        "outputId": "afddb11c-8dc4-4bb9-dae9-43214c59c03a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "xl_file = pd.ExcelFile('Combined.xlsx')\n",
        "\n",
        "sheets = {sheet_name: xl_file.parse(sheet_name) \n",
        "          for sheet_name in xl_file.sheet_names}\n",
        "\n",
        "dataframe = sheets['Policy']\n",
        "\n",
        "print('Sheets in the dataset:   ', sheets.keys())\n",
        "print('Number of regulations in the dataset: ', len(dataframe), '\\n')\n",
        "\n",
        "print(dataframe.head())\n",
        "# print('\\n', dataframe.info(), '\\n')\n",
        "\n",
        "combined_dataset = {}\n",
        "for key in dataframe:\n",
        "    dataframe[key]=dataframe[key].astype('str')\n",
        "    combined_dataset[key] = list(dataframe[key])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sheets in the dataset:    dict_keys(['Cases', 'Policy', 'HyperParam'])\n",
            "Number of regulations in the dataset:  23923 \n",
            "\n",
            "      ID  ISO            COUNTRY  ... Label_delta Label_percent  Label_3class\n",
            "0   1448  TUR             Turkey  ...         0.0           0.0          -1.0\n",
            "1  15613  GNQ  Equatorial Guinea  ...         0.0           0.0          -1.0\n",
            "2   9941  TJK         Tajikistan  ...         0.0           0.0          -1.0\n",
            "3  12714  GNQ  Equatorial Guinea  ...         0.0           0.0          -1.0\n",
            "4  12715  GNQ  Equatorial Guinea  ...         0.0           0.0          -1.0\n",
            "\n",
            "[5 rows x 30 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXijvUImUQ0g"
      },
      "source": [
        "id2label = {}\n",
        "for i in range(len(combined_dataset['ID'])):\n",
        "    id2label[int(combined_dataset['ID'][i])] = combined_dataset['Label_percent'][i]\n",
        "\n",
        "labels = []\n",
        "for id in not_null_ids:\n",
        "    if id2label[id] == '0' or id2label[id] == '1':\n",
        "        labels.append(int(id2label[id]))\n",
        "    else:\n",
        "        labels.append(-1)\n",
        "        # The label is NAN!"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfqf87dKJcbC",
        "outputId": "99744e8e-303a-47e5-a146-a2e711d2cb19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ids: not_null_ids\n",
        "# features: \n",
        "#   - message_embeddings\n",
        "#   - categories\n",
        "#   - measures\n",
        "#   - log_types\n",
        "# labels: \n",
        "#   - labels\n",
        "\n",
        "print('Not null ids dimension: ', len(not_null_ids))\n",
        "print('Log type dimension: ', len(log_types))\n",
        "print('Category dimension: ', len(categories), len(categories[0]))\n",
        "print('Measure dimension: ', len(measures), len(measures[0]))\n",
        "print('Message Embedding dimension: ', len(message_embeddings), len(message_embeddings[0]))\n",
        "print('Label dimension: ', len(labels))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not null ids dimension:  23799\n",
            "Log type dimension:  23799\n",
            "Category dimension:  23799 6\n",
            "Measure dimension:  23799 35\n",
            "Message Embedding dimension:  23799 768\n",
            "Label dimension:  23799\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}